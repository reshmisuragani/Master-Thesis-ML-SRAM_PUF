{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7boF61Htd-mR"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DllV-XLYeLHM",
    "outputId": "6d106315-7a49-4a3d-cd31-40d1c285c854"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3199 images belonging to 50 classes.\n",
      "Found 550 images belonging to 50 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen_aug =  ImageDataGenerator(width_shift_range=0.15,\n",
    "        height_shift_range=0.15, shear_range=0.15,\n",
    "        validation_split=0.15,\n",
    "        rescale=1./255)\n",
    "\n",
    "test_datagen_aug =  ImageDataGenerator(width_shift_range=0.15,validation_split=0.5,\n",
    "        height_shift_range=0.15, shear_range=0.15,\n",
    "        zoom_range=0.15,\n",
    "      \n",
    "        rescale=1./255)\n",
    "\n",
    "\n",
    "train_data = train_datagen_aug.flow_from_directory(r'D:\\Uni-passau\\thesis-smalldataset\\dataset-50\\train',target_size=(512,512), subset='training',\n",
    "                                                       batch_size=50, class_mode='categorical')\n",
    "valid_data = train_datagen_aug.flow_from_directory(r'D:\\Uni-passau\\thesis-smalldataset\\dataset-50\\train',target_size=(512,512),  subset='validation'\n",
    "                                                       ,batch_size=20, class_mode='categorical')\n",
    "#valid_data = test_datagen_aug.flow_from_directory(r'/content/drive/MyDrive/dataset-50/nor-dataset-50/test/',target_size=(256,256), \n",
    "                                                    #  batch_size=32, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JpR1jtJN8Jed"
   },
   "outputs": [],
   "source": [
    "import keras.backend as k\n",
    "import numpy as np\n",
    "import random\n",
    "seed = 12\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mHxdHDJheWJu",
    "outputId": "03e083c1-c93a-41c0-de4c-4eddaa574798"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 512, 512, 8)       2912      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 512, 512, 48)      9648      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 256, 256, 48)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 256, 256, 128)     55424     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 256, 256, 128)     512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 128, 128, 192)     221376    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128, 128, 192)     768       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 64, 64, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 64, 64, 192)       331968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 64, 64, 192)       768       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 32, 32, 192)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 196608)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              201327616 \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 50)                12850     \n",
      "=================================================================\n",
      "Total params: 202,626,114\n",
      "Trainable params: 202,622,018\n",
      "Non-trainable params: 4,096\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.regularizers import l2\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import GaussianNoise\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(filters = 8, kernel_size = (11,11), kernel_regularizer=l2(0.0001), padding = 'Same', activation ='relu', input_shape = (512,512,3)))\n",
    "model.add(tf.keras.layers.Conv2D(filters = 48, kernel_size = (5,5), kernel_regularizer=l2(0.0001), padding = 'Same', activation ='relu'))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2), strides = 2))\n",
    "model.add(tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3),kernel_regularizer=l2(0.0001), padding = 'Same', activation ='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2), strides= 2))\n",
    "model.add(tf.keras.layers.Conv2D(filters = 192, kernel_size = (3,3), kernel_regularizer=l2(0.0001), padding = 'Same', activation ='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2), strides= 2))\n",
    "model.add(tf.keras.layers.Conv2D(filters = 192, kernel_size = (3,3), kernel_regularizer=l2(0.0001), padding = 'Same', activation ='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2), strides= 2))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(1024, activation = \"relu\", kernel_regularizer=l2(0.0001)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dense(512, activation = \"relu\", kernel_regularizer=l2(0.0001)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dense(256, activation = \"relu\", kernel_regularizer=l2(0.0001)))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "model.add(tf.keras.layers.Dense(50, activation = \"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "h6gRMbVBeg68"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import CSVLogger\n",
    "\n",
    "csv = CSVLogger(\"/content/drive/MyDrive/dataset-50/nor-dataset-50/data-agu/50-model-augu_history_log(augu).csv\", append=True)\n",
    "es1= tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',patience=5, restore_best_weights=True)\n",
    "mc = ModelCheckpoint('/content/drive/MyDrive/dataset-50/nor-dataset-50/data-agu/50-cnnmodel(augu).h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Nu756mkfeytj"
   },
   "outputs": [],
   "source": [
    "\n",
    "adam = tf.keras.optimizers.Adam(learning_rate = 0.01, decay = 0.9)\n",
    "model.compile(optimizer = adam, loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0RdGWtuRcDgr",
    "outputId": "d0b0c5b6-6fb5-4bdc-bd1d-7b14922749b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "64/64 [==============================] - 213s 3s/step - loss: 11.2916 - accuracy: 0.1013 - val_loss: 56.9573 - val_accuracy: 0.0200\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.02000, saving model to /content/drive/MyDrive/dataset-50/nor-dataset-50/data-agu/50-cnnmodel(augu).h5\n",
      "Epoch 2/300\n",
      "64/64 [==============================] - 224s 3s/step - loss: 11.0002 - accuracy: 0.1606 - val_loss: 15.5951 - val_accuracy: 0.0200\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.02000\n",
      "Epoch 3/300\n",
      "64/64 [==============================] - 226s 4s/step - loss: 10.7254 - accuracy: 0.1878 - val_loss: 11.9607 - val_accuracy: 0.0818\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.02000 to 0.08182, saving model to /content/drive/MyDrive/dataset-50/nor-dataset-50/data-agu/50-cnnmodel(augu).h5\n",
      "Epoch 4/300\n",
      "64/64 [==============================] - 226s 4s/step - loss: 10.3813 - accuracy: 0.2631 - val_loss: 10.9799 - val_accuracy: 0.1000\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.08182 to 0.10000, saving model to /content/drive/MyDrive/dataset-50/nor-dataset-50/data-agu/50-cnnmodel(augu).h5\n",
      "Epoch 5/300\n",
      "64/64 [==============================] - 224s 3s/step - loss: 10.2155 - accuracy: 0.3028 - val_loss: 10.7817 - val_accuracy: 0.1655\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.10000 to 0.16545, saving model to /content/drive/MyDrive/dataset-50/nor-dataset-50/data-agu/50-cnnmodel(augu).h5\n",
      "Epoch 6/300\n",
      "64/64 [==============================] - 220s 3s/step - loss: 9.9552 - accuracy: 0.3566 - val_loss: 10.9196 - val_accuracy: 0.1164\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.16545\n",
      "Epoch 7/300\n",
      "64/64 [==============================] - 217s 3s/step - loss: 9.7648 - accuracy: 0.4131 - val_loss: 9.9085 - val_accuracy: 0.3818\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.16545 to 0.38182, saving model to /content/drive/MyDrive/dataset-50/nor-dataset-50/data-agu/50-cnnmodel(augu).h5\n",
      "Epoch 8/300\n",
      "64/64 [==============================] - 205s 3s/step - loss: 9.5950 - accuracy: 0.4641 - val_loss: 9.6894 - val_accuracy: 0.4400\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.38182 to 0.44000, saving model to /content/drive/MyDrive/dataset-50/nor-dataset-50/data-agu/50-cnnmodel(augu).h5\n",
      "Epoch 9/300\n",
      "64/64 [==============================] - 207s 3s/step - loss: 9.5096 - accuracy: 0.4775 - val_loss: 9.5841 - val_accuracy: 0.4618\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.44000 to 0.46182, saving model to /content/drive/MyDrive/dataset-50/nor-dataset-50/data-agu/50-cnnmodel(augu).h5\n",
      "Epoch 10/300\n",
      "64/64 [==============================] - 206s 3s/step - loss: 9.3639 - accuracy: 0.5100 - val_loss: 9.7372 - val_accuracy: 0.3545\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.46182\n",
      "Epoch 11/300\n",
      "64/64 [==============================] - 202s 3s/step - loss: 9.1970 - accuracy: 0.5591 - val_loss: 10.1145 - val_accuracy: 0.2527\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.46182\n",
      "Epoch 12/300\n",
      "64/64 [==============================] - 202s 3s/step - loss: 9.1763 - accuracy: 0.5578 - val_loss: 9.7308 - val_accuracy: 0.3273\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.46182\n",
      "Epoch 13/300\n",
      "64/64 [==============================] - 202s 3s/step - loss: 9.0274 - accuracy: 0.5941 - val_loss: 8.9188 - val_accuracy: 0.6909\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.46182 to 0.69091, saving model to /content/drive/MyDrive/dataset-50/nor-dataset-50/data-agu/50-cnnmodel(augu).h5\n",
      "Epoch 14/300\n",
      "64/64 [==============================] - 207s 3s/step - loss: 8.9605 - accuracy: 0.6159 - val_loss: 8.7437 - val_accuracy: 0.7327\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.69091 to 0.73273, saving model to /content/drive/MyDrive/dataset-50/nor-dataset-50/data-agu/50-cnnmodel(augu).h5\n",
      "Epoch 15/300\n",
      "64/64 [==============================] - 205s 3s/step - loss: 8.8747 - accuracy: 0.6484 - val_loss: 9.2147 - val_accuracy: 0.4982\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.73273\n",
      "Epoch 16/300\n",
      "64/64 [==============================] - 200s 3s/step - loss: 8.8204 - accuracy: 0.6444 - val_loss: 8.6465 - val_accuracy: 0.7582\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.73273 to 0.75818, saving model to /content/drive/MyDrive/dataset-50/nor-dataset-50/data-agu/50-cnnmodel(augu).h5\n",
      "Epoch 17/300\n",
      "64/64 [==============================] - 204s 3s/step - loss: 8.6992 - accuracy: 0.6666 - val_loss: 9.5885 - val_accuracy: 0.3509\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.75818\n",
      "Epoch 18/300\n",
      "64/64 [==============================] - 201s 3s/step - loss: 8.6343 - accuracy: 0.6875 - val_loss: 8.4920 - val_accuracy: 0.7655\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.75818 to 0.76545, saving model to /content/drive/MyDrive/dataset-50/nor-dataset-50/data-agu/50-cnnmodel(augu).h5\n",
      "Epoch 19/300\n",
      "64/64 [==============================] - 203s 3s/step - loss: 8.6084 - accuracy: 0.6803 - val_loss: 8.6654 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.76545\n",
      "Epoch 20/300\n",
      "64/64 [==============================] - 199s 3s/step - loss: 8.5352 - accuracy: 0.7088 - val_loss: 8.3051 - val_accuracy: 0.8418\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.76545 to 0.84182, saving model to /content/drive/MyDrive/dataset-50/nor-dataset-50/data-agu/50-cnnmodel(augu).h5\n",
      "Epoch 21/300\n",
      "64/64 [==============================] - 204s 3s/step - loss: 8.5240 - accuracy: 0.7069 - val_loss: 8.7755 - val_accuracy: 0.5727\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.84182\n",
      "Epoch 22/300\n",
      "64/64 [==============================] - 201s 3s/step - loss: 8.3880 - accuracy: 0.7337 - val_loss: 8.2359 - val_accuracy: 0.8727\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.84182 to 0.87273, saving model to /content/drive/MyDrive/dataset-50/nor-dataset-50/data-agu/50-cnnmodel(augu).h5\n",
      "Epoch 23/300\n",
      "64/64 [==============================] - 203s 3s/step - loss: 8.3538 - accuracy: 0.7403 - val_loss: 8.1147 - val_accuracy: 0.8545\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.87273\n",
      "Epoch 24/300\n",
      "64/64 [==============================] - 201s 3s/step - loss: 8.2892 - accuracy: 0.7525 - val_loss: 8.0907 - val_accuracy: 0.8691\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.87273\n",
      "Epoch 25/300\n",
      "64/64 [==============================] - 200s 3s/step - loss: 8.2422 - accuracy: 0.7597 - val_loss: 8.0583 - val_accuracy: 0.8709\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.87273\n",
      "Epoch 26/300\n",
      "64/64 [==============================] - 201s 3s/step - loss: 8.1937 - accuracy: 0.7819 - val_loss: 8.1611 - val_accuracy: 0.8055\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.87273\n",
      "Epoch 27/300\n",
      "64/64 [==============================] - 201s 3s/step - loss: 8.1379 - accuracy: 0.7922 - val_loss: 8.0096 - val_accuracy: 0.8964\n",
      "\n",
      "Epoch 00027: val_accuracy improved from 0.87273 to 0.89636, saving model to /content/drive/MyDrive/dataset-50/nor-dataset-50/data-agu/50-cnnmodel(augu).h5\n",
      "Epoch 28/300\n",
      "64/64 [==============================] - 208s 3s/step - loss: 8.1126 - accuracy: 0.7872 - val_loss: 8.1029 - val_accuracy: 0.7945\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.89636\n",
      "Epoch 29/300\n",
      "64/64 [==============================] - 203s 3s/step - loss: 8.0563 - accuracy: 0.7900 - val_loss: 7.9760 - val_accuracy: 0.8545\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.89636\n",
      "Epoch 30/300\n",
      "64/64 [==============================] - 202s 3s/step - loss: 8.0461 - accuracy: 0.7972 - val_loss: 7.8941 - val_accuracy: 0.8709\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.89636\n",
      "Epoch 31/300\n",
      "64/64 [==============================] - 202s 3s/step - loss: 7.9813 - accuracy: 0.8125 - val_loss: 7.7933 - val_accuracy: 0.8891\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.89636\n",
      "Epoch 32/300\n",
      "64/64 [==============================] - 200s 3s/step - loss: 7.9524 - accuracy: 0.8081 - val_loss: 7.8490 - val_accuracy: 0.8764\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.89636\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data,epochs=300,shuffle=True,validation_data=valid_data,callbacks=[csv,es1,mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EFpnlPyEzhe0",
    "outputId": "a25f9ee0-54a6-40b8-f5e5-0566e52ec393"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "64/64 [==============================] - 201s 3s/step - loss: 8.1060 - accuracy: 0.7872 - val_loss: 8.8636 - val_accuracy: 0.4745\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89636\n",
      "Epoch 2/300\n",
      "64/64 [==============================] - 197s 3s/step - loss: 8.0588 - accuracy: 0.7962 - val_loss: 7.9178 - val_accuracy: 0.8873\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.89636\n",
      "Epoch 3/300\n",
      "64/64 [==============================] - 198s 3s/step - loss: 8.0012 - accuracy: 0.8144 - val_loss: 7.8682 - val_accuracy: 0.8945\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.89636\n",
      "Epoch 4/300\n",
      "64/64 [==============================] - 197s 3s/step - loss: 7.9812 - accuracy: 0.8134 - val_loss: 8.4694 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.89636\n",
      "Epoch 5/300\n",
      "64/64 [==============================] - 195s 3s/step - loss: 7.9741 - accuracy: 0.8047 - val_loss: 7.7768 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.89636 to 0.90000, saving model to /content/drive/MyDrive/dataset-50/nor-dataset-50/data-agu/50-cnnmodel(augu).h5\n",
      "Epoch 6/300\n",
      "64/64 [==============================] - 203s 3s/step - loss: 7.9616 - accuracy: 0.8062 - val_loss: 7.7941 - val_accuracy: 0.8873\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.90000\n",
      "Epoch 7/300\n",
      "64/64 [==============================] - 199s 3s/step - loss: 7.8796 - accuracy: 0.8244 - val_loss: 7.6987 - val_accuracy: 0.9145\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.90000 to 0.91455, saving model to /content/drive/MyDrive/dataset-50/nor-dataset-50/data-agu/50-cnnmodel(augu).h5\n",
      "Epoch 8/300\n",
      "64/64 [==============================] - 197s 3s/step - loss: 7.9004 - accuracy: 0.8119 - val_loss: 7.6770 - val_accuracy: 0.9236\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.91455 to 0.92364, saving model to /content/drive/MyDrive/dataset-50/nor-dataset-50/data-agu/50-cnnmodel(augu).h5\n",
      "Epoch 9/300\n",
      "64/64 [==============================] - 203s 3s/step - loss: 7.8343 - accuracy: 0.8250 - val_loss: 7.6981 - val_accuracy: 0.8982\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.92364\n",
      "Epoch 10/300\n",
      "64/64 [==============================] - 200s 3s/step - loss: 7.8214 - accuracy: 0.8281 - val_loss: 7.6372 - val_accuracy: 0.8964\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.92364\n",
      "Epoch 11/300\n",
      "64/64 [==============================] - 200s 3s/step - loss: 7.7541 - accuracy: 0.8406 - val_loss: 7.6135 - val_accuracy: 0.9127\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.92364\n",
      "Epoch 12/300\n",
      "64/64 [==============================] - 196s 3s/step - loss: 7.7542 - accuracy: 0.8341 - val_loss: 7.8590 - val_accuracy: 0.8091\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.92364\n",
      "Epoch 13/300\n",
      "64/64 [==============================] - 196s 3s/step - loss: 7.6953 - accuracy: 0.8516 - val_loss: 7.5806 - val_accuracy: 0.8982\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.92364\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data,epochs=300,shuffle=True,validation_data=valid_data,callbacks=[csv,es1,mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "RYnKTzzw2VxH"
   },
   "outputs": [],
   "source": [
    "model.save_weights(r'/content/drive/MyDrive/dataset-50/nor-dataset-50/data-agu/cnn-augu-50_model-weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "QBDnieHqKvLv"
   },
   "outputs": [],
   "source": [
    "model.load_weights(r'D:\\Uni-passau\\thesis-results\\50-dataset\\normal-cnn-augu\\cnn-augu-50_model-weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i2bZiwmzywYX",
    "outputId": "7f662b28-b486-4522-ae35-a1948dbb1679"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 973s 15s/step - loss: 7.2565 - accuracy: 0.9318\n",
      "12/12 [==============================] - 156s 13s/step - loss: 7.3942 - accuracy: 0.8972\n",
      "train_Accuracy: 93.18%\n",
      "valid_Accuracy: 89.72%\n"
     ]
    }
   ],
   "source": [
    "train_acc = model.evaluate(train_data)\n",
    "val_acc = model.evaluate(valid_data)\n",
    "print(\"train_Accuracy: %.2f%%\" % (train_acc[1]*100))\n",
    "print(\"valid_Accuracy: %.2f%%\" % (val_acc[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 108s 4s/step - loss: 7.2189 - accuracy: 0.9491\n",
      "valid_Accuracy: 94.91%\n"
     ]
    }
   ],
   "source": [
    "val_acc = model.evaluate(valid_data)\n",
    "print(\"valid_Accuracy: %.2f%%\" % (val_acc[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "EYGt4bKtfToH"
   },
   "outputs": [],
   "source": [
    "test_datagen_nor = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen_aug =  ImageDataGenerator(width_shift_range=0.15,validation_split=0.5,\n",
    "        height_shift_range=0.15, shear_range=0.15,\n",
    "      \n",
    "        rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PWrWYlb__1oz"
   },
   "outputs": [],
   "source": [
    "## normal datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dQGSS_y1_UsK",
    "outputId": "4d087a5b-0ed9-490a-f3e1-a269464a8559"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1300 images belonging to 50 classes.\n",
      "163/163 [==============================] - 32s 194ms/step - loss: 1.5635 - accuracy: 0.9331\n",
      "Test_Accuracy: 93.31%\n"
     ]
    }
   ],
   "source": [
    "test_genrator_aug = test_datagen_aug.flow_from_directory( r'/content/drive/MyDrive/dataset-50/nor-dataset-50/test',\n",
    "        target_size=(256,256),\n",
    "        batch_size=8,\n",
    "        class_mode='categorical')\n",
    "test_acc = model.evaluate(test_genrator_aug)\n",
    "print(\"Test_Accuracy: %.2f%%\" % (test_acc[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U8hyMq_1_3qe"
   },
   "outputs": [],
   "source": [
    "## normal data augumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jtshpr1Ij8Sl",
    "outputId": "b1eb9313-bb89-45ea-ac52-795350ef3893"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1300 images belonging to 50 classes.\n",
      "17/17 [==============================] - 69s 4s/step - loss: 7.1764 - accuracy: 0.9477\n",
      "Test_Accuracy: 94.77%\n"
     ]
    }
   ],
   "source": [
    "test_genrator_aug = test_datagen_aug.flow_from_directory( r'/content/drive/MyDrive/dataset-50/nor-dataset-50/test',\n",
    "        target_size=(512,512),\n",
    "        batch_size=80,\n",
    "        class_mode='categorical')\n",
    "test_acc = model.evaluate(test_genrator_aug)\n",
    "print(\"Test_Accuracy: %.2f%%\" % (test_acc[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V1Zb-qjJBomA"
   },
   "outputs": [],
   "source": [
    "## gaussian noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GqJ0X-fK3wN0",
    "outputId": "0d947539-8d62-48b8-dedc-d631696f9b89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1300 images belonging to 50 classes.\n",
      "17/17 [==============================] - 840s 52s/step - loss: 9.1659 - accuracy: 0.2392\n",
      "Test_Accuracy: 23.92%\n"
     ]
    }
   ],
   "source": [
    "test_genrator_gau_nor = test_datagen_nor.flow_from_directory( r'/content/drive/MyDrive/dataset-50/gaussian-50/test',\n",
    "        target_size=(512,512),\n",
    "        batch_size=80,\n",
    "        class_mode='categorical')\n",
    "test_acc = model.evaluate(test_genrator_gau_nor)\n",
    "print(\"Test_Accuracy: %.2f%%\" % (test_acc[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H6CKEfCGBqs6"
   },
   "outputs": [],
   "source": [
    "## gaussian noise augumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v8LMtlVW3zGk",
    "outputId": "6bff70de-8845-4228-ba35-3a8abd582c88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1300 images belonging to 50 classes.\n",
      "17/17 [==============================] - 102s 6s/step - loss: 9.0516 - accuracy: 0.3223\n",
      "Test_Accuracy: 32.23%\n"
     ]
    }
   ],
   "source": [
    "test_genrator_gau_augmen = test_datagen_aug.flow_from_directory( r'/content/drive/MyDrive/dataset-50/gaussian-50/test',\n",
    "        target_size=(512,512),\n",
    "        batch_size=80,\n",
    "        class_mode='categorical')\n",
    "test_acc = model.evaluate(test_genrator_gau_augmen)\n",
    "print(\"Test_Accuracy: %.2f%%\" % (test_acc[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GH4OZft5BwNv"
   },
   "outputs": [],
   "source": [
    "## salt and pepper noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-_So-kER3_tu",
    "outputId": "98c19032-028a-459a-d9da-55f71770c2f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1300 images belonging to 50 classes.\n",
      "17/17 [==============================] - 806s 49s/step - loss: 9.6809 - accuracy: 0.2015\n",
      "Test_Accuracy: 20.15%\n"
     ]
    }
   ],
   "source": [
    "test_genrator_salt = test_datagen_nor.flow_from_directory( r'/content/drive/MyDrive/dataset-50/saltandpepper',\n",
    "        target_size=(512,512),\n",
    "        batch_size=80,\n",
    "        class_mode='categorical')\n",
    "test_acc = model.evaluate(test_genrator_salt)\n",
    "print(\"Test_Accuracy: %.2f%%\" % (test_acc[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EQ1n8OOCBygz"
   },
   "outputs": [],
   "source": [
    "## 20% corrupted resposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h7YzPLVE4Cd1",
    "outputId": "35054cd3-8c5c-47ca-e6c5-de198485dc9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1300 images belonging to 50 classes.\n",
      " 6/22 [=======>......................] - ETA: 3:34 - loss: 20.4078 - accuracy: 0.0361"
     ]
    }
   ],
   "source": [
    "test_corrupted1= test_datagen_nor.flow_from_directory( r'D:\\Uni-passau\\thesis-smalldataset\\corrupted-20',\n",
    "       target_size=(512,512),\n",
    "        batch_size=60,\n",
    "        class_mode='categorical')\n",
    "test_acc = model.evaluate(test_corrupted1)\n",
    "print(\"Test_Accuracy: %.2f%%\" % (test_acc[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 25 % corrupted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "icEN44V5B9CQ",
    "outputId": "0f4dc216-7293-408c-f648-7f2f8679dc6b"
   },
   "outputs": [],
   "source": [
    "test_genrator_corrupted = test_datagen_nor.flow_from_directory( r'D:\\Uni-passau\\thesis-smalldataset\\corrupted-25\\test'target_size=(512,512),\n",
    "        batch_size=80,\n",
    "        class_mode='categorical')\n",
    "test_acc = model.evaluate(test_genrator_corrupted)\n",
    "print(\"Test_Accuracy: %.2f%%\" % (test_acc[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V-ALGsP3B2pg"
   },
   "outputs": [],
   "source": [
    "## 50 corrupted resposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7d6SlPHLAvTJ",
    "outputId": "bd0ff176-29dd-4d78-ece9-e8472901c78e"
   },
   "outputs": [],
   "source": [
    "test_corrupted2= test_datagen_nor.flow_from_directory( r'D:\\Uni-passau\\thesis-smalldataset\\corrupted-50\\test',\n",
    "        target_size=(512,512),\n",
    "        batch_size=80,\n",
    "        class_mode='categorical')\n",
    "test_acc = model.evaluate(test_corrupted2)\n",
    "print(\"Test_Accuracy: %.2f%%\" % (test_acc[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nC9tkYw9fOt6"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.savefig('/content/drive/MyDrive/dataset-50/nor-dataset-50/data-agu/cnn-gaussain-accuracy.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6pHxyuX-fJ-r"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.savefig('/content/drive/MyDrive/dataset-50/nor-dataset-50/data-agu/cnn-gaussain-loss.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1300 images belonging to 50 classes.\n",
      "65/65 [==============================] - 258s 4s/step - loss: 7.3869 - accuracy: 0.9015\n",
      "Test_Accuracy: 90.15%\n"
     ]
    }
   ],
   "source": [
    "test_genrator_aug = test_datagen_nor.flow_from_directory( r'D:\\Uni-passau\\thesis-smalldataset\\dataset-50\\test',\n",
    "        target_size=(512,512),\n",
    "        batch_size=20,\n",
    "        class_mode='categorical')\n",
    "test_acc = model.evaluate(test_genrator_aug)\n",
    "print(\"Test_Accuracy: %.2f%%\" % (test_acc[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1300 images belonging to 50 classes.\n"
     ]
    }
   ],
   "source": [
    "test_genrator_nor = test_datagen_aug.flow_from_directory( r'D:\\Uni-passau\\thesis-smalldataset\\dataset-50\\test',\n",
    "        target_size=(512,512),\n",
    "        batch_size=50,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "x_test =[]\n",
    "y_test =[]\n",
    "len = int(1300/50)\n",
    "print(len)\n",
    "for i in range(len):\n",
    "  x,y = next(test_genrator_nor)\n",
    "  x_test.append(x)\n",
    "  y_test.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 50, 50) (26, 50, 512, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X_test =np.array(x_test)\n",
    "Y_test = np.array(y_test)\n",
    "print(Y_test.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1300, 50) (1300, 512, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "n,batches,hei,wid,col=np.array(X_test).shape\n",
    "X=np.array(X_test).reshape(n*batches,hei,wid,col)\n",
    "x,y,z=np.array(Y_test).shape\n",
    "Y =np.array(Y_test).reshape(x*y,z)\n",
    "print(Y.shape,X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X)\n",
    "# Convert predictions classes to one hot vectors \n",
    "Y_pred_classes = np.argmax(Y_pred,axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_classes = np.argmax(Y,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_classes, Y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "normal-cnn-augu-50.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
